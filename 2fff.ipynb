{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddd\n"
     ]
    }
   ],
   "source": [
    "print('ddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подгружаем .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем все креды\n",
    "src_host = os.environ.get('DB_SOURCE_HOST')\n",
    "src_port = os.environ.get('DB_SOURCE_PORT')\n",
    "src_username = os.environ.get('DB_SOURCE_USER')\n",
    "src_password = os.environ.get('DB_SOURCE_PASSWORD')\n",
    "src_db = os.environ.get('DB_SOURCE_NAME') \n",
    "\n",
    "dst_host = os.environ.get('DB_DESTINATION_HOST')\n",
    "dst_port = os.environ.get('DB_DESTINATION_PORT')\n",
    "dst_username = os.environ.get('DB_DESTINATION_USER')\n",
    "dst_password = os.environ.get('DB_DESTINATION_PASSWORD')\n",
    "dst_db = os.environ.get('DB_DESTINATION_NAME')\n",
    "\n",
    "s3_bucket = os.environ.get('S3_BUCKET_NAME')\n",
    "s3_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "s3_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим соединения\n",
    "src_conn = create_engine(f'postgresql://{src_username}:{src_password}@{src_host}:{src_port}/{src_db}')\n",
    "dst_conn = create_engine(f'postgresql://{dst_username}:{dst_password}@{dst_host}:{dst_port}/{dst_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    SplineTransformer, \n",
    "    QuantileTransformer, \n",
    "    RobustScaler,\n",
    "    PolynomialFeatures,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "\n",
    "TABLE_NAME = 'clean_users_churn'\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>type</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>...</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>tech_support</th>\n",
       "      <th>streaming_tv</th>\n",
       "      <th>streaming_movies</th>\n",
       "      <th>gender</th>\n",
       "      <th>senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id customer_id begin_date   end_date            type paperless_billing   \n",
       "0   1  7590-VHVEG 2020-01-01        NaT  Month-to-month               Yes  \\\n",
       "1   2  5575-GNVDE 2017-04-01        NaT        One year                No   \n",
       "2   3  3668-QPYBK 2019-10-01 2019-12-01  Month-to-month               Yes   \n",
       "3   4  7795-CFOCW 2016-05-01        NaT        One year                No   \n",
       "4   5  9237-HQITU 2019-09-01 2019-11-01  Month-to-month               Yes   \n",
       "\n",
       "              payment_method  monthly_charges  total_charges internet_service   \n",
       "0           Electronic check            29.85          29.85              DSL  \\\n",
       "1               Mailed check            56.95        1889.50              DSL   \n",
       "2               Mailed check            53.85         108.15              DSL   \n",
       "3  Bank transfer (automatic)            42.30        1840.75              DSL   \n",
       "4           Electronic check            70.70         151.65      Fiber optic   \n",
       "\n",
       "   ... device_protection tech_support streaming_tv streaming_movies  gender   \n",
       "0  ...                No           No           No               No  Female  \\\n",
       "1  ...               Yes           No           No               No    Male   \n",
       "2  ...                No           No           No               No    Male   \n",
       "3  ...               Yes          Yes           No               No    Male   \n",
       "4  ...                No           No           No               No  Female   \n",
       "\n",
       "  senior_citizen partner  dependents multiple_lines target  \n",
       "0              0     Yes          No             No      0  \n",
       "1              0      No          No             No      0  \n",
       "2              0      No          No             No      1  \n",
       "3              0      No          No             No      0  \n",
       "4              0      No          No             No      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from autofeat import AutoFeatRegressor,AutoFeatClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] # список признаков вашей модели\n",
    "target = ['target'] # колонка с таргетом вашей модели\n",
    "cat_features = [\n",
    "    'paperless_billing',\n",
    "    'payment_method',\n",
    "    'internet_service',\n",
    "    'online_security',\n",
    "    'online_backup',\n",
    "    'device_protection',\n",
    "    'tech_support',\n",
    "    'streaming_tv',\n",
    "    'streaming_movies',\n",
    "    'gender',\n",
    "    'senior_citizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'multiple_lines',\n",
    "]\n",
    "num_features = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "features = cat_features + num_features\n",
    "split_column = \"begin_date\"\n",
    "test_size = 0.2\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target],  # теперь df[target] не пустой\n",
    "    test_size=test_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем недостающие импорты в начале файла\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 210\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# Загрузка данных (замените на свой источник)\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# Запуск пайплайна\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     main(df)\n",
      "File \u001b[0;32m~/mle_projects/.venv_name/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/.venv_name/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/mle_projects/.venv_name/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/.venv_name/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/mle_projects/.venv_name/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_data.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         select *\n",
    "            from tags\n",
    "            join runs on runs.run_uuid = '403a6c9521a04b9db76588e60b26c605'\n",
    "                and runs.lifecycle_stage = 'active'\n",
    "                and runs.status = 'FINISHED'\n",
    "                and tags.value = '403a6c9521a04b9db76588e60b26c605'\n",
    "                and tags.key = 'mlflow.parentRunId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  # Добавляем импорт\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Tracking URI: http://127.0.0.1:5000\n",
      "/tmp/ipykernel_372780/3242878903.py:105: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflc = MLflowCallback(\n",
      "[I 2025-04-06 18:45:51,661] Using an existing study with name 'churn_model' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0aee09dc9249ac988b8ca6277f64d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 18:45:56,676] Trial 160 finished with value: 0.8388387017135562 and parameters: {'learning_rate': 0.039628872956278094, 'depth': 3, 'l2_leaf_reg': 1.9111495549607778, 'random_strength': 0.7059264707492978}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:01,154] Trial 161 finished with value: 0.8374116162946659 and parameters: {'learning_rate': 0.028059377926204825, 'depth': 2, 'l2_leaf_reg': 1.701165201119097, 'random_strength': 0.5569517773615004}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:05,960] Trial 162 finished with value: 0.838068143328752 and parameters: {'learning_rate': 0.060063294065786234, 'depth': 2, 'l2_leaf_reg': 2.194116537489349, 'random_strength': 0.8372374166605827}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:09,500] Trial 163 finished with value: 0.8378831716822899 and parameters: {'learning_rate': 0.05049556095304804, 'depth': 5, 'l2_leaf_reg': 1.8265563690472266, 'random_strength': 1.228017366491797}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:13,718] Trial 164 finished with value: 0.8392334835185182 and parameters: {'learning_rate': 0.031019782002905703, 'depth': 3, 'l2_leaf_reg': 1.390868166424252, 'random_strength': 0.3768414030641431}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:17,940] Trial 165 finished with value: 0.8332938802422432 and parameters: {'learning_rate': 0.016681667292642487, 'depth': 3, 'l2_leaf_reg': 2.0100838623028094, 'random_strength': 1.9503088335271552}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:20,995] Trial 166 finished with value: 0.8373107568821495 and parameters: {'learning_rate': 0.07863855745690129, 'depth': 2, 'l2_leaf_reg': 1.1335693865720176, 'random_strength': 1.5138756255599861}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:25,498] Trial 167 finished with value: 0.8382470935177505 and parameters: {'learning_rate': 0.0420383011007688, 'depth': 3, 'l2_leaf_reg': 0.7556009270313234, 'random_strength': 2.856214489683878}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:29,202] Trial 168 finished with value: 0.837906881171053 and parameters: {'learning_rate': 0.047414094968556246, 'depth': 4, 'l2_leaf_reg': 0.5314111047670182, 'random_strength': 2.600675617140512}. Best is trial 41 with value: 0.8419467071459137.\n",
      "[I 2025-04-06 18:46:32,962] Trial 169 finished with value: 0.8376129587786076 and parameters: {'learning_rate': 0.05506223362061476, 'depth': 2, 'l2_leaf_reg': 0.8958653540703052, 'random_strength': 3.1434630527669944}. Best is trial 41 with value: 0.8419467071459137.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/.venv_name/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Registered model 'best_churn_model' already exists. Creating a new version of this model...\n",
      "2025/04/06 18:46:58 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: best_churn_model, version 12\n",
      "Created version '12' of model 'best_churn_model'.\n",
      "/home/mle-user/mle_projects/.venv_name/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Registered model 'best_churn_model' already exists. Creating a new version of this model...\n",
      "2025/04/06 18:46:58 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: best_churn_model, version 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization complete!\n",
      "Optimization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '13' of model 'best_churn_model'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    log_loss\n",
    ")\n",
    "from collections import defaultdict\n",
    "import mlflow\n",
    "import logging\n",
    "\n",
    "# Настройка логов\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Проверка переменных окружени\n",
    "os.environ.update({\n",
    "    \"MLFLOW_S3_ENDPOINT_URL\": \"https://storage.yandexcloud.net\",\n",
    "    \"AWS_ACCESS_KEY_ID\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    \"AWS_SECRET_ACCESS_KEY\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "})\n",
    "# Настройка MLflow\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "pip_requirements = \"../requirements.txt\"\n",
    "logger.info(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "input_example = X_test[:10]\n",
    "# Параметры эксперимента\n",
    "EXPERIMENT_NAME = 'churn_denis_putov_www'\n",
    "RUN_NAME = \"model_bayesian_search_@2222\"\n",
    "STUDY_DB_NAME = \"sqlite:///local.study.db\"\n",
    "STUDY_NAME = \"churn_model\"\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.1, 5),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 5),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"task_type\": \"CPU\",\n",
    "        \"random_seed\": 0,\n",
    "        \"iterations\": 300,\n",
    "        \"verbose\": False,\n",
    "        \"cat_features\": cat_features\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**param)\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=0)\n",
    "    \n",
    "    metrics = defaultdict(list)\n",
    "    \n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        train_X = X_train.iloc[train_index]\n",
    "        train_y = y_train.iloc[train_index]\n",
    "        val_X = X_train.iloc[val_index]\n",
    "        val_y = y_train.iloc[val_index]\n",
    "        \n",
    "        model.fit(\n",
    "            train_X,\n",
    "            train_y,\n",
    "            eval_set=(val_X, val_y),\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        probas = model.predict_proba(val_X)[:, 1]\n",
    "        prediction = model.predict(val_X)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(val_y, prediction, normalize='all').ravel()\n",
    "        \n",
    "        metrics[\"err1\"].append(fp)\n",
    "        metrics[\"err2\"].append(fn)\n",
    "        metrics[\"auc\"].append(roc_auc_score(val_y, probas))\n",
    "        metrics[\"precision\"].append(precision_score(val_y, prediction, zero_division=0))\n",
    "        metrics[\"recall\"].append(recall_score(val_y, prediction, zero_division=0))\n",
    "        metrics[\"f1\"].append(f1_score(val_y, prediction, zero_division=0))\n",
    "        metrics[\"logloss\"].append(log_loss(val_y, probas))\n",
    "    \n",
    "    # Агрегация метрик\n",
    "    trial.set_user_attr(\"err1\", np.mean(metrics[\"err1\"]))\n",
    "    trial.set_user_attr(\"err2\", np.mean(metrics[\"err2\"]))\n",
    "    trial.set_user_attr(\"precision\", np.mean(metrics[\"precision\"]))\n",
    "    trial.set_user_attr(\"recall\", np.mean(metrics[\"recall\"]))\n",
    "    trial.set_user_attr(\"f1\", np.mean(metrics[\"f1\"]))\n",
    "    trial.set_user_attr(\"logloss\", np.mean(metrics[\"logloss\"]))\n",
    "    \n",
    "    return np.mean(metrics[\"auc\"])\n",
    "\n",
    "# Основной блок выполнения\n",
    "if __name__ == \"__main__\":\n",
    "    # Создаем родительский запуск\n",
    "    with mlflow.start_run(run_name=RUN_NAME) as parent_run:\n",
    "        parent_run_id = parent_run.info.run_id\n",
    "        \n",
    "        # 4. Исправьте тег MLFLOW_PARENT_RUN_ID\n",
    "        mlflc = MLflowCallback(\n",
    "            tracking_uri=mlflow.get_tracking_uri(),\n",
    "            metric_name=\"auc\",\n",
    "            create_experiment=True,\n",
    "            mlflow_kwargs={\n",
    "                'experiment_name': EXPERIMENT_NAME,\n",
    "                'tags': {\n",
    "                    'mlflow.parentRunId': parent_run_id,  # Правильное имя тега\n",
    "                    \"mlflow.runName\": \"optuna_trial\"\n",
    "                },\n",
    "                'nested': True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Создание исследования Optuna\n",
    "        study = optuna.create_study(\n",
    "            sampler=optuna.samplers.TPESampler(),\n",
    "            direction=\"maximize\",\n",
    "            study_name=STUDY_NAME,\n",
    "            storage=STUDY_DB_NAME,\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        \n",
    "        # Запуск оптимизации\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=10,\n",
    "            callbacks=[mlflc],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        # Логирование результатов в родительский запуск\n",
    "        mlflow.log_params(study.best_params)\n",
    "        mlflow.log_metrics({\n",
    "            \"best_auc\": study.best_value,\n",
    "            \"err1\": study.best_trial.user_attrs[\"err1\"],\n",
    "            \"err2\": study.best_trial.user_attrs[\"err2\"]\n",
    "        })\n",
    "        \n",
    "        # Логирование модели в родительский запуск\n",
    "        best_model = CatBoostClassifier(**study.best_params, cat_features=cat_features)\n",
    "        best_model.fit(X_train, y_train, verbose=False)\n",
    "        # Создание поддиректории для артефактов\n",
    "        artifact_path = \"cv\"\n",
    "        os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "        # 1. Сохранение модели в формате pickle\n",
    "        model_pkl_path = os.path.join(artifact_path, \"model.pkl\")\n",
    "        with open(model_pkl_path, \"wb\") as f:\n",
    "            pickle.dump(best_model, f)\n",
    "\n",
    "        # 2. Логирование модели через MLflow\n",
    "        mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=\"cv\",\n",
    "        registered_model_name=\"best_churn_model\",\n",
    "        signature = infer_signature(X_train, best_model.predict(X_train)),\n",
    "        input_example=input_example\n",
    "        )\n",
    "    \n",
    "        mlflow.catboost.log_model(\n",
    "            cb_model=best_model,\n",
    "            artifact_path=\"cv\",\n",
    "            registered_model_name=\"best_churn_model\",\n",
    "            pip_requirements=pip_requirements,\n",
    "            input_example=input_example,\n",
    "            metadata={'model_type': 'monthly'},\n",
    "            signature = infer_signature(X_train, best_model.predict(X_train))\n",
    "        )\n",
    "        print(\"Optimization complete!\")\n",
    "    \n",
    "    # Логирование CatBoost модели\n",
    "\n",
    "\n",
    "    print(\"Optimization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
